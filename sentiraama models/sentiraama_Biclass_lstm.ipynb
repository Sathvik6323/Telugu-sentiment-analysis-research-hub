{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/SourabhMagadum/Hindi-Sentiment-Analysis/blob/master/Hindi_sentiment_analysis%20best.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T06:53:27.752764Z",
     "iopub.status.busy": "2024-05-02T06:53:27.752100Z",
     "iopub.status.idle": "2024-05-02T06:53:40.734463Z",
     "shell.execute_reply": "2024-05-02T06:53:40.733236Z",
     "shell.execute_reply.started": "2024-05-02T06:53:27.752735Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras_preprocessing\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.10/site-packages (from keras_preprocessing) (1.26.4)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from keras_preprocessing) (1.16.0)\n",
      "Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m575.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: keras_preprocessing\n",
      "Successfully installed keras_preprocessing-1.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "gxbgrTR5-t7r",
    "outputId": "cf4515f8-2ef0-4f00-b740-0fcfd8e84ec9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.python.keras import Sequential\n",
    "from keras.layers import  Dense, Embedding, LSTM, Bidirectional,GRU\n",
    "# from tensorflow.python.keras.layers import Dense, Embedding, LSTM, GRU \n",
    "#\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "#\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras import optimizers\n",
    "from keras import layers\n",
    "# from tensorflow.python.keras import layers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.status.busy": "2024-05-02T06:53:40.801811Z",
     "iopub.status.idle": "2024-05-02T06:53:40.802196Z",
     "shell.execute_reply": "2024-05-02T06:53:40.802018Z",
     "shell.execute_reply.started": "2024-05-02T06:53:40.802003Z"
    },
    "id": "_ZISB5UF_x4Y"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "df = pd.read_csv('/kaggle/input/sentiraama/merged_file_cleaned.csv')\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "TuyzqoczAc4J",
    "outputId": "8b71f70e-d789-4f42-c795-a80ff3646749"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>నేను గత సంవత్సరం ఈ పుస్తకం చదివాను  ఇది చదవే ఒ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ఈ పుస్తకం నా యువ పాఠకులకు 'ముందుకు సాగడం ప్రార...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ఒక ప్రశంసలు పొందిన రచయితకు ఆత్మహత్య లేఖ  వ్రాయ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ఈ పుస్తకం ప్రధానంగా భారతీయులకు చాలా అద్భుతమైన...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>మంచి భవిష్యత్తు కావాలని కలలుకంటున్న ఒక సామాన్య...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  నేను గత సంవత్సరం ఈ పుస్తకం చదివాను  ఇది చదవే ఒ...       1\n",
       "1  ఈ పుస్తకం నా యువ పాఠకులకు 'ముందుకు సాగడం ప్రార...       1\n",
       "2  ఒక ప్రశంసలు పొందిన రచయితకు ఆత్మహత్య లేఖ  వ్రాయ...       0\n",
       "3  ఈ పుస్తకం ప్రధానంగా భారతీయులకు చాలా అద్భుతమైన...       1\n",
       "4  మంచి భవిష్యత్తు కావాలని కలలుకంటున్న ఒక సామాన్య...       1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "i_mSkGSsA12b",
    "outputId": "eb2c63a7-6a23-4a67-a0ea-99d2e24e740b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(672, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hpqLRMiiJJWm"
   },
   "outputs": [],
   "source": [
    "y = df[\"target\"]\n",
    "X = df.drop([\"target\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Kq9LdZSMBWKV",
    "outputId": "58d45d99-41ad-4db6-8bb5-f66678b2f03a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>హలో   నేను రికనెక్ట్ LED TV గురించి సమీక్ష ఇస్...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>‘కిక్’ కళ్యాణ్ దొంగతనాలు మానేసి పోలీసు ఉద్యోగం...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>బాలీవుడ్లో వచ్చిన హంటర్ సినిమాకు రీమేక్గా తెలు...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>నా షెల్ఫ్ లో సేకరించిన పుస్తకాలలో ఉత్తమ పుస్తక...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>ఈ TV మీకు సహజమైన అనుభూతిని అందిస్తుంది  LED TV...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "652  హలో   నేను రికనెక్ట్ LED TV గురించి సమీక్ష ఇస్...\n",
       "257  ‘కిక్’ కళ్యాణ్ దొంగతనాలు మానేసి పోలీసు ఉద్యోగం...\n",
       "298  బాలీవుడ్లో వచ్చిన హంటర్ సినిమాకు రీమేక్గా తెలు...\n",
       "12   నా షెల్ఫ్ లో సేకరించిన పుస్తకాలలో ఉత్తమ పుస్తక...\n",
       "658  ఈ TV మీకు సహజమైన అనుభూతిని అందిస్తుంది  LED TV..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 70/15/15 train/test/val split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=1)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ScF16hE0S8Z9"
   },
   "outputs": [],
   "source": [
    "tk = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{\"}~\\t\\n')\n",
    "\n",
    "\n",
    "tk.fit_on_texts(X['text'])\n",
    "\n",
    "# + 1 for unknown token\n",
    "vocab_size = len(tk.word_index) +1\n",
    "\n",
    "X_train_seq = tk.texts_to_sequences(X_train['text'])\n",
    "X_test_seq = tk.texts_to_sequences(X_test['text'])\n",
    "X_val_seq = tk.texts_to_sequences(X_val['text'])\n",
    "# Initializing max length of sentence to 20 words\n",
    "max_length = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32693"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2024-05-02T07:28:36.517904Z",
     "iopub.status.busy": "2024-05-02T07:28:36.517196Z",
     "iopub.status.idle": "2024-05-02T07:28:36.522216Z",
     "shell.execute_reply": "2024-05-02T07:28:36.521162Z",
     "shell.execute_reply.started": "2024-05-02T07:28:36.517874Z"
    },
    "id": "UreIQTGecPOI",
    "outputId": "835b4b05-aab0-42af-8560-76b9793ad1dc"
   },
   "outputs": [],
   "source": [
    "# tk.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2024-05-02T07:28:38.682140Z",
     "iopub.status.busy": "2024-05-02T07:28:38.681301Z",
     "iopub.status.idle": "2024-05-02T07:28:38.686612Z",
     "shell.execute_reply": "2024-05-02T07:28:38.685654Z",
     "shell.execute_reply.started": "2024-05-02T07:28:38.682104Z"
    },
    "id": "G0fHuNn8clLk",
    "outputId": "9aa54b9c-d3b5-4c41-f885-f2cb9b13df25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32693\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2024-05-02T07:28:42.913946Z",
     "iopub.status.busy": "2024-05-02T07:28:42.913292Z",
     "iopub.status.idle": "2024-05-02T07:28:42.918065Z",
     "shell.execute_reply": "2024-05-02T07:28:42.916957Z",
     "shell.execute_reply.started": "2024-05-02T07:28:42.913910Z"
    },
    "id": "X_bXPd9Kd0Ph",
    "outputId": "ae8c362e-c3cb-4958-8e9b-528241fcce4b"
   },
   "outputs": [],
   "source": [
    "# X_train_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iLO5BDDaffdU"
   },
   "outputs": [],
   "source": [
    "#padding the sequences to make all the input sequences of the same length\n",
    "\n",
    "X_train_seq_pad = pad_sequences(X_train_seq, maxlen=max_length, padding='post')\n",
    "X_test_seq_pad = pad_sequences(X_test_seq, maxlen=max_length,padding='post')\n",
    "X_val_seq_pad = pad_sequences(X_val_seq, maxlen=max_length,padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xNDBIRzEpkpr"
   },
   "outputs": [],
   "source": [
    "\n",
    "le = LabelEncoder()\n",
    "y_train_le = le.fit_transform(y_train)\n",
    "y_test_le = le.transform(y_test)\n",
    "y_val_le = le.transform(y_val)\n",
    "y_train_oh = to_categorical(y_train_le)\n",
    "y_test_oh = to_categorical(y_test_le)\n",
    "y_val_oh = to_categorical(y_val_le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3144,    46, 32543, ...,   198, 32545,  9060],\n",
       "       [   13,   593,  1876, ...,   205, 18989,  2587],\n",
       "       [21263,     6,   307, ...,  2427,  4325,    66],\n",
       "       ...,\n",
       "       [   32,   250,   103, ...,   541,   283,   103],\n",
       "       [18251,    18,  4415, ...,  5184,   230,  3883],\n",
       "       [   35,  2416,   103, ...,   837,    63, 13555]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_seq_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dims = 256\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, emb_dims, input_length=max_length, embeddings_regularizer=tf.keras.regularizers.l2(0.0001)))\n",
    "model.add(LSTM(units=16, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T07:29:59.329573Z",
     "iopub.status.busy": "2024-05-02T07:29:59.329150Z",
     "iopub.status.idle": "2024-05-02T07:30:05.738225Z",
     "shell.execute_reply": "2024-05-02T07:30:05.737380Z",
     "shell.execute_reply.started": "2024-05-02T07:29:59.329543Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9987 - loss: 0.0407 - val_accuracy: 0.5814 - val_loss: 1.5027\n",
      "Epoch 2/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0365 - val_accuracy: 0.5814 - val_loss: 1.4488\n",
      "Epoch 3/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0357 - val_accuracy: 0.5814 - val_loss: 1.4252\n",
      "Epoch 4/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0347 - val_accuracy: 0.5698 - val_loss: 1.4165\n",
      "Epoch 5/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0334 - val_accuracy: 0.5698 - val_loss: 1.4243\n",
      "Epoch 6/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0325 - val_accuracy: 0.5698 - val_loss: 1.4382\n",
      "Epoch 7/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0308 - val_accuracy: 0.5698 - val_loss: 1.4333\n",
      "Epoch 8/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0312 - val_accuracy: 0.5698 - val_loss: 1.4371\n",
      "Epoch 9/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0294 - val_accuracy: 0.5698 - val_loss: 1.4511\n",
      "Epoch 10/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0280 - val_accuracy: 0.5698 - val_loss: 1.4732\n",
      "Epoch 11/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0273 - val_accuracy: 0.5814 - val_loss: 1.5009\n",
      "Epoch 12/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0265 - val_accuracy: 0.5930 - val_loss: 1.5350\n",
      "Epoch 13/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0260 - val_accuracy: 0.5930 - val_loss: 1.5423\n",
      "Epoch 14/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0258 - val_accuracy: 0.5930 - val_loss: 1.5669\n",
      "Epoch 15/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0254 - val_accuracy: 0.6047 - val_loss: 1.5005\n",
      "Epoch 16/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0240 - val_accuracy: 0.6047 - val_loss: 1.4558\n",
      "Epoch 17/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0243 - val_accuracy: 0.6047 - val_loss: 1.4432\n",
      "Epoch 18/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9963 - loss: 0.0322 - val_accuracy: 0.6047 - val_loss: 1.4473\n",
      "Epoch 19/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0234 - val_accuracy: 0.6163 - val_loss: 1.4654\n",
      "Epoch 20/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0234 - val_accuracy: 0.6047 - val_loss: 1.4783\n",
      "Epoch 21/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9987 - loss: 0.0254 - val_accuracy: 0.6163 - val_loss: 1.4847\n",
      "Epoch 22/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0219 - val_accuracy: 0.6163 - val_loss: 1.4867\n",
      "Epoch 23/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0231 - val_accuracy: 0.5930 - val_loss: 1.5137\n",
      "Epoch 24/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0223 - val_accuracy: 0.5814 - val_loss: 1.5508\n",
      "Epoch 25/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0206 - val_accuracy: 0.5814 - val_loss: 1.5878\n",
      "Epoch 26/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0199 - val_accuracy: 0.5930 - val_loss: 1.6209\n",
      "Epoch 27/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0197 - val_accuracy: 0.6047 - val_loss: 1.6423\n",
      "Epoch 28/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0200 - val_accuracy: 0.5930 - val_loss: 1.6585\n",
      "Epoch 29/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0200 - val_accuracy: 0.5814 - val_loss: 1.6765\n",
      "Epoch 30/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9979 - loss: 0.0292 - val_accuracy: 0.5581 - val_loss: 1.6068\n",
      "Epoch 31/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0195 - val_accuracy: 0.5581 - val_loss: 1.5215\n",
      "Epoch 32/32\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9992 - loss: 0.0216 - val_accuracy: 0.5698 - val_loss: 1.4721\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_train_seq_pad and y_train_oh are your training data (sequences and one-hot encoded labels)\n",
    "history = model.fit(X_train_seq_pad, y_train_oh, epochs=32, batch_size=128,validation_data=(X_val_seq_pad, y_val_oh), shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2024-05-02T07:30:10.830114Z",
     "iopub.status.busy": "2024-05-02T07:30:10.829259Z",
     "iopub.status.idle": "2024-05-02T07:30:10.851257Z",
     "shell.execute_reply": "2024-05-02T07:30:10.850343Z",
     "shell.execute_reply.started": "2024-05-02T07:30:10.830079Z"
    },
    "id": "jJMNuByCRbBL",
    "outputId": "8c37a135-8696-4aec-e375-86bbb7eef8dc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,369,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">17,472</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │     \u001b[38;5;34m8,369,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │        \u001b[38;5;34m17,472\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m34\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,160,744</span> (95.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,160,744\u001b[0m (95.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,386,914</span> (31.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,386,914\u001b[0m (31.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,773,830</span> (63.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m16,773,830\u001b[0m (63.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T07:32:10.485960Z",
     "iopub.status.busy": "2024-05-02T07:32:10.485002Z",
     "iopub.status.idle": "2024-05-02T07:32:10.490773Z",
     "shell.execute_reply": "2024-05-02T07:32:10.489654Z",
     "shell.execute_reply.started": "2024-05-02T07:32:10.485924Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T07:32:33.597214Z",
     "iopub.status.busy": "2024-05-02T07:32:33.596762Z",
     "iopub.status.idle": "2024-05-02T07:32:34.130830Z",
     "shell.execute_reply": "2024-05-02T07:32:34.129943Z",
     "shell.execute_reply.started": "2024-05-02T07:32:33.597160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_seq_pad)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Assuming y_pred is one-hot encoded\n",
    "y_test_classes = le.inverse_transform(y_test_le)  # Convert back to original classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-02T07:32:35.872801Z",
     "iopub.status.busy": "2024-05-02T07:32:35.872437Z",
     "iopub.status.idle": "2024-05-02T07:32:35.887274Z",
     "shell.execute_reply": "2024-05-02T07:32:35.886243Z",
     "shell.execute_reply.started": "2024-05-02T07:32:35.872775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.7719\n",
      "Precision: 0.7749\n",
      "Recall: 0.7727\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_test_classes, y_pred_classes, average='macro')  # Macro averaging for imbalanced data (optional)\n",
    "precision = precision_score(y_test_classes, y_pred_classes, average='macro')  # Macro averaging\n",
    "recall = recall_score(y_test_classes, y_pred_classes, average='macro')  # Macro averaging\n",
    "\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2024-05-02T07:32:41.410440Z",
     "iopub.status.busy": "2024-05-02T07:32:41.410054Z",
     "iopub.status.idle": "2024-05-02T07:32:41.526133Z",
     "shell.execute_reply": "2024-05-02T07:32:41.525214Z",
     "shell.execute_reply.started": "2024-05-02T07:32:41.410410Z"
    },
    "id": "k6YKpCP3NQrd",
    "outputId": "5ebe8afa-0fbe-46d3-94f3-851bdcf56ac7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7620 - loss: 0.8662\n",
      "/n\n",
      "Test accuracy of word embeddings model: 77.23%\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test_seq_pad, y_test_oh)\n",
    "print('/n')\n",
    "print('Test accuracy of word embeddings model: {0:.2f}%'.format(results[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2024-05-02T07:32:42.885324Z",
     "iopub.status.busy": "2024-05-02T07:32:42.884902Z",
     "iopub.status.idle": "2024-05-02T07:32:42.989087Z",
     "shell.execute_reply": "2024-05-02T07:32:42.988091Z",
     "shell.execute_reply.started": "2024-05-02T07:32:42.885291Z"
    },
    "id": "uQm45MSMHy9O",
    "outputId": "610a24af-a45d-4323-baaa-ca604cfe4a42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5896 - loss: 1.3884\n",
      "/n\n",
      "Validation accuracy of word embeddings model: 56.98%\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_val_seq_pad, y_val_oh)\n",
    "print('/n')\n",
    "print('Validation accuracy of word embeddings model: {0:.2f}%'.format(results[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f6Ur8gO9J147"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMQ5we7Aqxtr1Fp5MWTm4e6",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Hindi sentiment analysis.ipynb",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4922258,
     "sourceId": 8287199,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4922536,
     "sourceId": 8287536,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
